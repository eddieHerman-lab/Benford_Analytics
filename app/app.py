import re
from io import BytesIO

import numpy as np
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
import streamlit as st
from reportlab.lib import colors
from reportlab.lib.pagesizes import letter
from reportlab.lib.styles import getSampleStyleSheet
from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Table, TableStyle
from scipy.stats import chisquare

# Configura√ß√£o da p√°gina
st.set_page_config(page_title="Benford Analytics", layout="wide",
                   initial_sidebar_state="expanded")


# Fun√ß√£o para extrair o primeiro d√≠gito com tratamento robusto
def extract_first_digit(x):
    """
    Extrai o primeiro d√≠gito significativo de um n√∫mero com normaliza√ß√£o robusta.
    Trata v√°rios formatos, incluindo moedas e valores formatados.
    """
    if pd.isna(x):  # Tratar NaN explicitamente
        return None

    try:
        # Converter para string primeiro para tratar formatos especiais
        # Usar str(x) para garantir que funciona com qualquer tipo (n√∫mero, string, etc.)
        x_str = str(x)

        # Remover caracteres n√£o num√©ricos (exceto ponto e v√≠rgula e sinal negativo)
        # Funciona para formatos como "R$ 1.234,56" ou "$1,234.56"
        # Adicionado tratamento para sinal negativo
        x_clean = re.sub(r'[^\d.,\-]', '', x_str)

        # Normalizar separadores (considerando formatos internacionais)
        if ',' in x_clean and '.' in x_clean:
            # Formato brasileiro: 1.234,56 -> remove '.', substitui ',' por '.'
            if x_clean.find(',') > x_clean.find('.'):
                x_clean = x_clean.replace('.', '').replace(',', '.')
            # Formato americano: 1,234.56 -> remove ','
            else:
                x_clean = x_clean.replace(',', '')
        # V√≠rgula como separador decimal e sem ponto (ex: "123,45")
        elif ',' in x_clean and '.' not in x_clean:
            x_clean = x_clean.replace(',', '.')

        # Tentar converter para float
        x_float = float(x_clean)

        # Lidar com zeros e negativos ap√≥s a convers√£o para float
        if x_float == 0:
            return None

        # Garantir que trabalhamos com o valor absoluto para o primeiro d√≠gito
        x_abs = abs(x_float)

        # Normalizar para obter o primeiro d√≠gito significativo
        # Trata casos como 0.00123 -> 1.23 ou 123.45 -> 1.23
        if x_abs < 1:
            while x_abs < 1:
                x_abs *= 10
        elif x_abs >= 10:
            while x_abs >= 10:
                x_abs /= 10

        # O primeiro d√≠gito √© a parte inteira
        first_digit = int(x_abs)

        # Deve estar entre 1 e 9. Se for 0 (acontece com n√∫meros muito pequenos tipo 0.000...)
        # a normaliza√ß√£o j√° deveria ter tratado, mas como seguran√ßa...
        if first_digit == 0:
            # Isso n√£o deve acontecer com a normaliza√ß√£o acima, mas √© um fallback
            return None  # Ou retornar 1 se assumirmos que 0.0...1 deve come√ßar com 1?

        return first_digit

    except (ValueError, TypeError, AttributeError):
        # Captura erros de convers√£o ou atributos inesperados
        return None


# Fun√ß√£o para normalizar os dados
def normalize_dataframe(df):
    """
    Prepara o DataFrame para an√°lise, normalizando valores e detectando colunas num√©ricas.
    """
    # Criar uma c√≥pia para evitar modificar o original
    df_clean = df.copy()

    # Lista para armazenar colunas potencialmente num√©ricas ap√≥s convers√£o
    potential_numeric_cols = []

    # Verificar cada coluna
    for col in df_clean.columns:
        # Se j√° √© num√©rica, adicionar √† lista e continuar
        if pd.api.types.is_numeric_dtype(df_clean[col]):
            potential_numeric_cols.append(col)
            continue

        # Se coluna de objeto (comum para strings)
        if pd.api.types.is_object_dtype(df_clean[col]) or pd.api.types.is_string_dtype(df_clean[col]):
            # Tentar converter valores formatados em n√∫meros usando a l√≥gica do extract_first_digit
            try:
                # Criar uma nova coluna com a tentativa de convers√£o para float
                # Reutilizamos a l√≥gica de limpeza do extract_first_digit para a convers√£o
                df_clean[f"{col}_numeric"] = df_clean[col].apply(
                    lambda x: None if pd.isna(x) or str(x).strip() == ''
                    else re.sub(r'[^\d.,\-+]', '', str(x).replace(',', '.'))  # Apply basic cleaning
                )

                # Tentativa final de converter para float, com errors='coerce' para transformar falhas em NaN
                df_clean[f"{col}_numeric"] = pd.to_numeric(
                    df_clean[f"{col}_numeric"], errors='coerce'
                )

                # Verificar se a nova coluna num√©rica tem valores v√°lidos (n√£o todos NaN)
                if not df_clean[f"{col}_numeric"].isna().all():
                    # Verificar quantos valores foram convertidos com sucesso
                    successfully_converted = df_clean[f"{col}_numeric"].notna().sum()
                    original_non_na = df_clean[col].notna().sum()

                    # Heur√≠stica: se uma fra√ß√£o razo√°vel dos valores originais n√£o nulos foi convertida
                    # Isso √© um indicador de que a coluna *poderia* ser num√©rica
                    if original_non_na > 0 and successfully_converted / original_non_na > 0.5:  # Ajuste este limiar se necess√°rio
                        potential_numeric_cols.append(f"{col}_numeric")
                        st.info(
                            f"A coluna '{col}' foi tratada e identificada como potencialmente num√©rica ('{col}_numeric').")
                    else:
                        # Se a convers√£o falhou para a maioria, remover a coluna tempor√°ria
                        df_clean = df_clean.drop(columns=[f"{col}_numeric"])
                        # st.info(f"Coluna '{col}' n√£o parece ser num√©rica ap√≥s tratamento.") # Opcional, pode poluir o log
                else:
                    # Se todos os valores resultaram em NaN ap√≥s a convers√£o, remover a coluna tempor√°ria
                    df_clean = df_clean.drop(columns=[f"{col}_numeric"])
                    # st.info(f"Coluna '{col}' n√£o parece ser num√©rica ap√≥s tratamento.") # Opcional

            except Exception as e:
                # Capturar e reportar erros durante o processo de convers√£o de uma coluna espec√≠fica
                st.warning(f"Erro inesperado ao tentar converter coluna '{col}': {str(e)}")
                # Garantir que a coluna tempor√°ria seja removida em caso de erro
                if f"{col}_numeric" in df_clean.columns:
                    df_clean = df_clean.drop(columns=[f"{col}_numeric"])

    # Remover colunas tempor√°rias que foram criadas mas n√£o identificadas como num√©ricas (seguran√ßa)
    cols_to_drop_temp = [c for c in df_clean.columns if c.endswith('_numeric') and c not in potential_numeric_cols]
    df_clean = df_clean.drop(columns=cols_to_drop_temp)

    return df_clean, potential_numeric_cols


# Fun√ß√£o para criar o PDF
def create_pdf(observed_counts, benford_dist, chi2, p_value, total_count, column_name, mad, sad):
    buffer = BytesIO()
    doc = SimpleDocTemplate(buffer, pagesize=letter)
    elements = []

    styles = getSampleStyleSheet()
    # Estilos b√°sicos
    title_style = styles['Heading1']
    subtitle_style = styles['Heading2']
    normal_style = styles['Normal']
    # Adicionar ou modificar estilos para a conclus√£o, se desejar cores/√™nfase
    h3_style = styles['Heading3']  # Estilo para subt√≠tulos menores

    # T√≠tulo e informa√ß√µes
    elements.append(Paragraph("Relat√≥rio de An√°lise pela Lei de Benford", title_style))
    elements.append(Spacer(1, 12))
    elements.append(Paragraph(f"Coluna analisada: {column_name}", subtitle_style))
    elements.append(Paragraph(f"Total de registros analisados: {total_count}", normal_style))  # Clarify 'analisados'
    elements.append(Spacer(1, 12))

    # Resultados do teste e m√©tricas de desvio
    elements.append(Paragraph("Resultados da An√°lise Estat√≠stica:", subtitle_style))
    elements.append(Paragraph(f"Estat√≠stica Chi¬≤: {chi2:.4f}", normal_style))
    elements.append(Paragraph(f"Valor-p: {p_value:.4f}", normal_style))
    # Adicionamos MAD e SAD
    elements.append(Paragraph(f"Mean Absolute Deviation (MAD): {mad * 100:.2f}%", normal_style))
    elements.append(Paragraph(f"Sum of Absolute Differences (SAD): {sad * 100:.2f}%", normal_style))

    # Conclus√£o baseada na nova l√≥gica (similar ao Streamlit)
    elements.append(Spacer(1, 12))
    elements.append(Paragraph("Conclus√£o da An√°lise:", subtitle_style))

    # Use os mesmos limiares definidos na l√≥gica do Streamlit
    mad_threshold_strict = 0.010
    mad_threshold_moderate = 0.005

    if p_value < 0.05:
        if mad >= mad_threshold_strict:
            conclusion_text = "ALTA SUSPEITA DE ANOMALIA/MANIPULA√á√ÉO üö®: Desvio estatisticamente significativo (p < {:.4f}) E tamanho m√©dio do desvio (MAD = {:.2f}%) considerado alto.".format(
                0.05, mad * 100)
            elements.append(Paragraph(conclusion_text, h3_style))  # Usando H3 para destacar
        elif mad >= mad_threshold_moderate:
            conclusion_text = "SUSPEITA MODERADA DE ANOMALIA ü§î: Desvio estatisticamente significativo (p < {:.4f}), mas tamanho m√©dio do desvio (MAD = {:.2f}%) moderado. Recomenda-se investiga√ß√£o e an√°lise contextual.".format(
                0.05, mad * 100)
            elements.append(Paragraph(conclusion_text, h3_style))  # Usando H3
        else:
            conclusion_text = "DESVIO ESTAT√çSTICO (BAIXA SUSPEITA) üìâ: Desvio estatisticamente significativo (p < {:.4f}), mas tamanho m√©dio do desvio (MAD = {:.2f}%) baixo. Isso pode ocorrer naturalmente em amostras grandes. Recomenda-se inspe√ß√£o visual e contexto.".format(
                0.05, mad * 100)
            elements.append(Paragraph(conclusion_text, normal_style))  # Estilo normal
    else:
        conclusion_text = "CONFORME ESPERADO ‚úÖ: Os dados seguem a Lei de Benford conforme esperado (p >= {:.4f}). N√£o h√° evid√™ncia estat√≠stica forte de anomalias nos primeiros d√≠gitos.".format(
            0.05)
        elements.append(Paragraph(conclusion_text, normal_style))  # Estilo normal

    elements.append(Spacer(1, 12))

    # Tabela detalhada
    data = [["D√≠gito", "Contagem", "Observado (%)", "Esperado (%)", "Diferen√ßa (%)"]]

    # Garantir que os dados da tabela estejam na ordem correta e completos (d√≠gitos 1-9)
    for d in range(1, 10):
        obs_count = observed_counts.get(d, 0)
        # Calcular porcentagens e diferen√ßas com base no total_count passado (registros v√°lidos)
        obs_pct = (obs_count / total_count) * 100 if total_count > 0 else 0
        # A distribui√ß√£o de Benford (benford_dist) j√° deve ser as propor√ß√µes (ex: 0.301)
        benford_pct = benford_dist[d - 1] * 100
        diff = obs_pct - benford_pct

        data.append([
            str(d),
            f"{obs_count:,.0f}",  # Formatando contagem
            f"{obs_pct:.2f}%",
            f"{benford_pct:.2f}%",
            f"{diff:+.2f}%"
        ])

    # Criar e estilizar a tabela
    table = Table(data)
    table.setStyle(TableStyle([
        ('BACKGROUND', (0, 0), (-1, 0), colors.grey),
        ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),
        ('ALIGN', (0, 0), (-1, -1), 'CENTER'),
        ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
        ('BOTTOMPADDING', (0, 0), (-1, 0), 12),
        ('BACKGROUND', (0, 1), (-1, -1), colors.beige),  # Cor para as linhas de dados
        ('GRID', (0, 0), (-1, -1), 1, colors.black)
    ]))

    elements.append(table)
    elements.append(Spacer(1, 12))

    # Informa√ß√µes sobre a Lei de Benford (existente)
    elements.append(Paragraph("Sobre a Lei de Benford:", subtitle_style))
    elements.append(Paragraph("""
    A Lei de Benford (tamb√©m conhecida como Lei do Primeiro D√≠gito) √© um fen√¥meno matem√°tico
    que descreve a distribui√ß√£o de frequ√™ncia do primeiro d√≠gito em muitos conjuntos de dados do mundo real.
    De acordo com esta lei, o d√≠gito 1 aparece como o primeiro d√≠gito em cerca
    de 30% dos casos, enquanto d√≠gitos maiores aparecem com frequ√™ncia cada vez menor.

    Um desvio significativo desta distribui√ß√£o pode indicar dados manipulados ou an√¥malos.
    O teste estat√≠stico aplicado (chi-quadrado) ajuda a quantificar o grau de conformidade
    dos dados com a distribui√ß√£o esperada pela Lei de Benford.
    As m√©tricas MAD (Mean Absolute Deviation) e SAD (Sum of Absolute Differences) fornecem
    uma medida do tamanho total do desvio em rela√ß√£o √† distribui√ß√£o esperada.
    """, normal_style))  # Adicionada men√ß√£o a MAD/SAD

    # Gerar o PDF
    doc.build(elements)
    return buffer


# Interface do usu√°rio em abas
tab1, tab2 = st.tabs(["An√°lise de Benford", "Sobre a Lei de Benford"])

with tab1:
    st.title("üìä An√°lise de Benford para Detec√ß√£o de Anomalias")

    # Upload do arquivo
    uploaded_file = st.file_uploader("Carregue seu arquivo (CSV ou Excel)",
                                     type=["csv", "xlsx", "xls", "ods"])

    if uploaded_file is not None:
        # Processar o arquivo
        try:
            # Obter a extens√£o do arquivo
            file_extension = uploaded_file.name.split('.')[-1].lower()

            df = None  # Inicializa df como None

            # L√≥gica para ler diferentes tipos de arquivo
            if file_extension == 'csv':
                # Tentar diferentes encodings para CSV (seu c√≥digo existente)
                encodings = ['utf-8', 'latin-1', 'ISO-8859-1', 'cp1252']
                for encoding in encodings:
                    try:
                        uploaded_file.seek(0)  # Volta o ponteiro para o in√≠cio para cada tentativa
                        df = pd.read_csv(uploaded_file, encoding=encoding)
                        # --- INSERIR WORKAROUND DA C√ìPIA AQUI (CSV) ---
                        df = pd.DataFrame(df.values, columns=df.columns, index=df.index)
                        st.success(f"Arquivo CSV lido com codifica√ß√£o {encoding}")
                        break
                    except Exception:
                        continue

                if df is None or df.empty:
                    st.error("N√£o foi poss√≠vel ler o arquivo CSV. Tente converter para Excel ou um encoding diferente.")
                    st.stop()

            # L√≥gica para ler arquivos Excel (.xlsx, .xls)
            elif file_extension in ['xlsx', 'xls']:
                try:
                    # Para Excel, tentamos m√∫ltiplos engines para compatibilidade
                    excel_engines = ['openpyxl', 'xlrd', 'pyxlsb']  # Ordem de prefer√™ncia
                    read_success = False

                    for engine_name in excel_engines:
                        try:
                            uploaded_file.seek(0)
                            xls = pd.ExcelFile(uploaded_file, engine=engine_name)
                            sheet_name = st.selectbox("Selecione a planilha:", xls.sheet_names)
                            df = pd.read_excel(uploaded_file, sheet_name=sheet_name, engine=engine_name)

                            # Aplicar workaround de c√≥pia
                            df = pd.DataFrame(df.values, columns=df.columns, index=df.index)
                            st.success(f"Arquivo Excel lido com engine '{engine_name}'.")
                            read_success = True
                            break  # Sai do loop se conseguir ler
                        except ImportError:
                            # Ignora se o engine n√£o est√° instalado, tenta o pr√≥ximo
                            continue
                        except Exception as e:
                            # Captura outros erros de leitura para este engine e tenta o pr√≥ximo
                            continue

                    if not read_success or df is None or df.empty:
                        st.error("N√£o foi poss√≠vel ler o arquivo Excel com nenhum engine dispon√≠vel.")
                        st.stop()

                except Exception as e_xl:
                    st.error(f"Erro ao processar arquivo Excel: {e_xl}")
                    st.stop()

            # L√≥gica para ler arquivos ODS (.ods)
            elif file_extension == 'ods':
                try:
                    uploaded_file.seek(0)
                    # Tente ler diretamente
                    df = pd.read_excel(uploaded_file, engine='odf')

                    # Se chegou aqui, a leitura foi bem-sucedida
                    # Aplicar workaround de c√≥pia
                    df = pd.DataFrame(df.values, columns=df.columns, index=df.index)
                    st.success("Arquivo ODS lido com sucesso.")

                except ImportError:
                    st.error("""
                       Para ler arquivos ODS (.ods), por favor instale a biblioteca `odfpy`.
                       Abra seu terminal e execute:
                       `pip install odfpy`
                       Reinicie o aplicativo Streamlit ap√≥s a instala√ß√£o.
                       """)
                    st.stop()  # Para a execu√ß√£o se a biblioteca n√£o estiver instalada

                except Exception as e_ods:
                    st.error(f"N√£o foi poss√≠vel ler o arquivo ODS: {e_ods}")
                    st.stop()

            else:
                st.error(f"Formato de arquivo n√£o suportado: .{file_extension}. Formatos aceitos: csv, xlsx, xls, ods")
                st.stop()

            # Mostrar dados
            st.subheader("Visualiza√ß√£o do Arquivo")
            st.dataframe(df.head())

            # Op√ß√µes avan√ßadas de preprocessamento
            with st.expander("Op√ß√µes Avan√ßadas de Preprocessamento"):
                skip_rows = st.number_input("Pular linhas iniciais", 0, 100, 0,
                                            help="N√∫mero de linhas a ignorar no in√≠cio do arquivo.")
                if skip_rows > 0 and len(df) > skip_rows:
                    df = df.iloc[skip_rows:].reset_index(drop=True)
                    st.write(f"Ignoradas {skip_rows} linhas iniciais.")

                # Op√ß√£o para remover linhas com valores nulos em *todas* as colunas
                if st.checkbox("Remover linhas completamente vazias"):
                    old_len = len(df)
                    df = df.dropna(how='all')
                    st.write(f"Removidas {old_len - len(df)} linhas vazias.")

                # Op√ß√£o para remover colunas espec√≠ficas
                if st.checkbox("Remover colunas selecionadas"):
                    cols_to_drop = st.multiselect("Selecione colunas para remover:", df.columns,
                                                  help="Selecione as colunas que n√£o devem ser consideradas na an√°lise ou pr√©-processamento.")
                    if cols_to_drop:
                        df = df.drop(columns=cols_to_drop)
                        st.write(f"Removidas {len(cols_to_drop)} colunas.")

            # Normaliza√ß√£o dos dados
            st.subheader("Sele√ß√£o da Coluna para An√°lise")
            with st.spinner("Identificando colunas num√©ricas..."):
                df_clean, potential_numeric_cols = normalize_dataframe(df)  # Usar o df_clean retornado

            if not potential_numeric_cols:
                st.error("Nenhuma coluna identificada como num√©rica no arquivo!")
                st.info(
                    "Dica: A ferramenta tenta converter colunas de texto com n√∫meros e formatos monet√°rios, mas pode n√£o reconhecer todos os formatos. Verifique se a coluna de interesse cont√©m dados num√©ricos v√°lidos.")
                st.stop()  # Parar a execu√ß√£o se n√£o houver colunas num√©ricas

            # Sele√ß√£o de coluna e an√°lise
            col = st.selectbox("Selecione a coluna para an√°lise:", potential_numeric_cols)

            # Op√ß√µes de an√°lise
            with st.expander("Op√ß√µes de An√°lise"):
                remove_zeros = st.checkbox("Ignorar valores iguais a zero", value=True,
                                           help="A Lei de Benford se aplica a n√∫meros positivos e significativos. Zeros geralmente n√£o s√£o inclu√≠dos.")
                remove_negatives = st.checkbox("Ignorar valores negativos", value=False,
                                               help="A Lei de Benford tradicionalmente considera o valor absoluto. Marque esta op√ß√£o para ignorar valores negativos.")
                # Futuramente: op√ß√£o para usar valor absoluto?

            # Bot√£o para iniciar an√°lise
            if st.button("üìä Iniciar An√°lise de Benford"):
                with st.spinner("Analisando dados..."):
                    # Preparar dados para an√°lise - usar df_clean que cont√©m colunas num√©ricas tratadas
                    analysis_data_series = df_clean[col].copy()

                    # Aplicar filtros conforme op√ß√µes
                    if remove_zeros:
                        analysis_data_series = analysis_data_series[analysis_data_series != 0]
                    if remove_negatives:
                        analysis_data_series = analysis_data_series[analysis_data_series > 0]
                    # Se n√£o remover negativos, talvez usar abs()? Decidi n√£o for√ßar abs() por padr√£o,
                    # deixando como op√ß√£o ou mantendo o filtro de negativos. A fun√ß√£o extract_first_digit j√° usa abs().

                    # Extrair primeiros d√≠gitos usando a fun√ß√£o robusta
                    # Aplicar extract_first_digit apenas aos valores n√£o-NaN
                    first_digits = analysis_data_series.dropna().apply(extract_first_digit).dropna()

                    if len(first_digits) < 100:  # Um n√∫mero razo√°vel de dados para an√°lise significativa
                        st.error(
                            f"Dados insuficientes para an√°lise de Benford ap√≥s filtragem ({len(first_digits)} registros v√°lidos). Recomenda-se pelo menos ~100 registros.")
                        st.stop()  # Parar se n√£o houver dados suficientes

                    # Mostrar estat√≠sticas b√°sicas
                    st.subheader("Estat√≠sticas B√°sicas")
                    stats_col1, stats_col2, stats_col3 = st.columns(3)
                    stats_col1.metric("Total de registros na coluna",
                                      f"{len(df_clean[col]):,}")  # Total na coluna antes de filtrar
                    stats_col2.metric("Registros v√°lidos para an√°lise",
                                      f"{len(first_digits):,}")  # Registros ap√≥s filtros e extra√ß√£o bem sucedida
                    stats_col3.metric("Registros ignorados/inv√°lidos",
                                      f"{len(df_clean[col]) - len(first_digits):,}")  # Diferen√ßa

                    # Contagem de d√≠gitos observados
                    observed = first_digits.value_counts().sort_index()

                    # Garantir que todos os d√≠gitos de 1 a 9 estejam representados (com contagem 0 se n√£o apareceram)
                    for d in range(1, 10):
                        if d not in observed.index:
                            observed[d] = 0
                    observed = observed.sort_index()

                    # Verificar se h√° dados v√°lidos para os d√≠gitos 1-9 (total_observed)
                    total_observed = observed.sum()
                    if total_observed == 0:  # Redundante se j√° checamos len(first_digits) > 0, mas boa pr√°tica
                        st.error("N√£o foram encontrados d√≠gitos v√°lidos (1-9) para an√°lise ap√≥s a extra√ß√£o!")
                        st.stop()

                    # Distribui√ß√£o esperada de Benford (em propor√ß√µes)
                    benford_proportions = np.log10(1 + 1 / np.arange(1, 10))
                    expected_counts = benford_proportions * total_observed

                    # Teste chi-quadrado - Usar apenas d√≠gitos com frequ√™ncias esperadas > 0
                    # O teste chi-quadrado padr√£o do scipy (chisquare) lida bem com zeros observados,
                    # mas espera frequ√™ncias esperadas > 0. Scipy recomenda exp > 5 para um bom ajuste.
                    # Vamos filtrar exp > 0 para evitar erros, mas alertar sobre baixa contagem esperada.
                    valid_digits_for_chi2 = [d for d in range(1, 10) if
                                             expected_counts[d - 1] > 0]  # Todos os d√≠gitos 1-9 ter√£o exp > 0
                    valid_obs_for_chi2 = [observed.get(d, 0) for d in valid_digits_for_chi2]
                    valid_exp_for_chi2 = [expected_counts[d - 1] for d in valid_digits_for_chi2]

                    # Alerta se frequ√™ncias esperadas s√£o baixas para alguns d√≠gitos (compromete o teste Chi¬≤)
                    low_expected_count_digits = [d for d in range(1, 10) if
                                                 expected_counts[d - 1] < 5 and expected_counts[d - 1] > 0]
                    if low_expected_count_digits:
                        st.warning(f"""
                         Aten√ß√£o: As frequ√™ncias esperadas para os d√≠gitos {low_expected_count_digits} s√£o menores que 5.
                         O teste Chi-Quadrado pode n√£o ser preciso nessas condi√ß√µes.
                         """)

                    if len(valid_obs_for_chi2) < 2:  # M√≠nimo de 2 categorias para o teste Chi¬≤
                        chi2 = float('nan')
                        p = float('nan')
                        st.warning(
                            "Dados insuficientes com frequ√™ncia esperada > 0 para realizar o teste estat√≠stico Chi-Quadrado.")
                    else:
                        try:
                            chi2, p = chisquare(valid_obs_for_chi2, valid_exp_for_chi2)
                        except Exception as e:
                            st.error(f"Erro ao calcular o teste Chi-Quadrado: {str(e)}")
                            chi2 = float('nan')
                            p = float('nan')

                    # Calcular m√©tricas de diferen√ßa
                    # MAD (Mean Absolute Deviation) - m√©dia dos desvios absolutos
                    observed_proportions = observed / total_observed
                    abs_diff = np.zeros(9)
                    for i in range(1, 10):
                        obs_prop = observed_proportions.get(i, 0)
                        benford_prop = benford_proportions[i - 1]
                        abs_diff[i - 1] = abs(obs_prop - benford_prop)

                    # Calcular MAD (Mean Absolute Deviation - Desvio Absoluto M√©dio)
                    mad = np.mean(abs_diff)

                    # Calcular SAD (Sum of Absolute Differences - Soma das Diferen√ßas Absolutas)
                    sad = np.sum(abs_diff)

                    # Definir limiares para MAD (baseados na literatura)
                    mad_threshold_close = 0.0015  # Aproximadamente conforme
                    mad_threshold_acceptable = 0.005  # Marginalmente conforme
                    mad_threshold_suspect = 0.010  # N√£o conforme / suspeito
                    mad_threshold_critical = 0.015  # Altamente suspeito

                    # Exibir resultados estat√≠sticos
                    st.subheader("Resultados Estat√≠sticos")

                    stat_cols = st.columns([1, 1, 1, 1])
                    stat_cols[0].metric("Estat√≠stica Chi¬≤", f"{chi2:.4f}" if not np.isnan(chi2) else "N/A")
                    stat_cols[1].metric("Valor-p", f"{p:.4f}" if not np.isnan(p) else "N/A")
                    stat_cols[2].metric("MAD", f"{mad * 100:.2f}%" if not np.isnan(mad) else "N/A")
                    stat_cols[3].metric("SAD", f"{sad * 100:.2f}%" if not np.isnan(sad) else "N/A")

                    # Interpreta√ß√£o dos resultados
                    st.subheader("Interpreta√ß√£o dos Resultados")

                    # Classificar o resultado com base no valor-p e MAD
                    if not np.isnan(p) and not np.isnan(mad):
                        if p < 0.05:  # Estatisticamente significativo
                            if mad >= mad_threshold_suspect:
                                st.error(
                                    "üö® **ALTA SUSPEITA DE ANOMALIA/MANIPULA√á√ÉO**: Desvio estatisticamente significativo (p < 0.05) E tamanho m√©dio do desvio (MAD) considerado alto.")
                            elif mad >= mad_threshold_acceptable:
                                st.warning(
                                    "ü§î **SUSPEITA MODERADA DE ANOMALIA**: Desvio estatisticamente significativo (p < 0.05), mas tamanho m√©dio do desvio (MAD) moderado. Recomenda-se investiga√ß√£o e an√°lise contextual.")
                            else:
                                st.info(
                                    "üìâ **DESVIO ESTAT√çSTICO (BAIXA SUSPEITA)**: Desvio estatisticamente significativo (p < 0.05), mas tamanho m√©dio do desvio (MAD) baixo. Isso pode ocorrer naturalmente em amostras grandes. Recomenda-se inspe√ß√£o visual e contexto.")
                        else:
                            st.success(
                                "‚úÖ **CONFORME ESPERADO**: Os dados seguem a Lei de Benford conforme esperado (p >= 0.05). N√£o h√° evid√™ncia estat√≠stica forte de anomalias nos primeiros d√≠gitos.")
                    else:
                        st.warning(
                            "‚ö†Ô∏è N√£o foi poss√≠vel realizar uma interpreta√ß√£o completa devido a limita√ß√µes nos dados.")

                    # Exibi√ß√£o de contexto
                    st.info("""
                            **Interpreta√ß√£o do MAD (Mean Absolute Deviation)**:
                            - < 0.0015: Forte conformidade com Benford
                            - 0.0015-0.005: Conformidade aceit√°vel
                            - 0.005-0.010: Conformidade marginal, poss√≠vel anomalia
                            - 0.010-0.015: N√£o conforme, suspeita moderada
                            - > 0.015: Forte suspeita de anomalia

                            **Interpreta√ß√£o do valor-p**:
                            Um valor-p < 0.05 indica um desvio estatisticamente significativo da distribui√ß√£o de Benford.
                            """)

                    # Visualiza√ß√£o: Gr√°fico de barras
                    st.subheader("Visualiza√ß√£o Comparativa")

                    # Prepara√ß√£o dos dados para visualiza√ß√£o
                    viz_data = pd.DataFrame({
                        'D√≠gito': range(1, 10),
                        'Observado (%)': [observed_proportions.get(d, 0) * 100 for d in range(1, 10)],
                        'Esperado (%)': benford_proportions * 100
                    })

                    # Criar o gr√°fico de barras
                    fig = px.bar(viz_data, x='D√≠gito', y=['Observado (%)', 'Esperado (%)'],
                                 barmode='group', title='Distribui√ß√£o dos Primeiros D√≠gitos',
                                 labels={'value': 'Porcentagem (%)', 'variable': 'Distribui√ß√£o'},
                                 color_discrete_sequence=['#5D69B1', '#52BCA3'])

                    # Adicionar linha horizontal para p-value
                    if not np.isnan(p):
                        fig.add_annotation(
                            xref="paper", yref="paper",
                            x=0.5, y=1.05,
                            text=f"Valor-p: {p:.4f} | MAD: {mad * 100:.2f}%",
                            showarrow=False,
                            font=dict(size=14)
                        )

                    st.plotly_chart(fig, use_container_width=True)

                    # Visualiza√ß√£o: Linha de discrep√¢ncia
                    st.subheader("Gr√°fico de Discrep√¢ncia")

                    # Calcular diferen√ßas
                    diff_data = pd.DataFrame({
                        'D√≠gito': range(1, 10),
                        'Diferen√ßa (Obs - Esp) %': [(observed_proportions.get(d, 0) - benford_proportions[d - 1]) * 100
                                                    for d in range(1, 10)]
                    })

                    # Criar gr√°fico de linha/√°rea para destacar discrep√¢ncias
                    fig_diff = go.Figure()

                    # Adicionar linha zero como refer√™ncia
                    fig_diff.add_trace(go.Scatter(
                        x=list(range(1, 10)),
                        y=[0] * 9,
                        mode='lines',
                        line=dict(color='black', dash='dash'),
                        name='Refer√™ncia'
                    ))

                    # Adicionar barras de diferen√ßa
                    fig_diff.add_trace(go.Bar(
                        x=diff_data['D√≠gito'],
                        y=diff_data['Diferen√ßa (Obs - Esp) %'],
                        marker_color=['red' if diff < 0 else 'green' for diff in diff_data['Diferen√ßa (Obs - Esp) %']],
                        name='Discrep√¢ncia'
                    ))

                    fig_diff.update_layout(
                        title='Discrep√¢ncia entre Distribui√ß√£o Observada e Lei de Benford',
                        xaxis_title='Primeiro D√≠gito',
                        yaxis_title='Diferen√ßa (Pontos Percentuais)',
                        xaxis=dict(tickmode='linear', tick0=1, dtick=1)
                    )

                    st.plotly_chart(fig_diff, use_container_width=True)

                    # Tabela detalhada
                    st.subheader("Tabela Detalhada")

                    # Criar tabela de resultados
                    result_table = pd.DataFrame({
                        'D√≠gito': range(1, 10),
                        'Contagem': [observed.get(d, 0) for d in range(1, 10)],
                        'Observado (%)': [observed_proportions.get(d, 0) * 100 for d in range(1, 10)],
                        'Esperado (%)': benford_proportions * 100,
                        'Diferen√ßa (p.p.)': [(observed_proportions.get(d, 0) - benford_proportions[d - 1]) * 100 for d
                                             in range(1, 10)]
                    })

                    # Formata√ß√£o da tabela
                    result_table['Contagem'] = result_table['Contagem'].map('{:,.0f}'.format)
                    result_table['Observado (%)'] = result_table['Observado (%)'].map('{:.2f}%'.format)
                    result_table['Esperado (%)'] = result_table['Esperado (%)'].map('{:.2f}%'.format)
                    result_table['Diferen√ßa (p.p.)'] = result_table['Diferen√ßa (p.p.)'].map('{:+.2f}'.format)

                    st.dataframe(result_table, hide_index=True)

                    # Gerar PDF do relat√≥rio
                    st.subheader("Exportar Relat√≥rio")

                    # Crie um dicion√°rio para mapear √≠ndices para contagens observadas
                    observed_counts_dict = {d: observed.get(d, 0) for d in range(1, 10)}

                    # Gerar PDF
                    pdf_buffer = create_pdf(
                        observed_counts=observed_counts_dict,
                        benford_dist=benford_proportions,
                        chi2=chi2,
                        p_value=p,
                        total_count=total_observed,
                        column_name=col,
                        mad=mad,
                        sad=sad
                    )

                    # Bot√£o para download do PDF
                    st.download_button(
                        label="üì• Baixar Relat√≥rio PDF",
                        data=pdf_buffer.getvalue(),
                        file_name=f"relatorio_benford_{col}.pdf",
                        mime="application/pdf"
                    )
        except Exception as analysis_error:
            st.error(f"Erro durante a an√°lise: {analysis_error}")

    with tab2:
        st.title("üìö Sobre a Lei de Benford")

        st.markdown("""
            ## O que √© a Lei de Benford?

            A **Lei de Benford**, tamb√©m conhecida como Lei do Primeiro D√≠gito, √© um fen√¥meno matem√°tico que descreve a distribui√ß√£o n√£o uniforme dos primeiros d√≠gitos em muitos conjuntos de dados do mundo real.

            Ao contr√°rio do que se poderia esperar intuitivamente (que cada d√≠gito de 1 a 9 teria igual probabilidade de ocorr√™ncia), a Lei de Benford prev√™ que:

            | Primeiro D√≠gito | Probabilidade |
            |-----------------|---------------|
            | 1               | 30.1%         |
            | 2               | 17.6%         |
            | 3               | 12.5%         |
            | 4               | 9.7%          |
            | 5               | 7.9%          |
            | 6               | 6.7%          |
            | 7               | 5.8%          |
            | 8               | 5.1%          |
            | 9               | 4.6%          |

            ### Aplica√ß√µes Pr√°ticas

            A Lei de Benford √© amplamente utilizada em:

            - **Auditoria financeira**: Identifica√ß√£o de fraudes cont√°beis
            - **An√°lise de dados eleitorais**: Detec√ß√£o de poss√≠veis manipula√ß√µes
            - **Valida√ß√£o de modelos cient√≠ficos**: Verifica√ß√£o da naturalidade dos dados
            - **An√°lise econ√¥mica**: Verifica√ß√£o da consist√™ncia de indicadores econ√¥micos
            - **Investiga√ß√µes fiscais**: Identifica√ß√£o de declara√ß√µes fiscais suspeitas

            ### Como funciona a an√°lise?

            A an√°lise pela Lei de Benford compara a distribui√ß√£o dos primeiros d√≠gitos de um conjunto de dados com a distribui√ß√£o te√≥rica esperada. Se houver desvios significativos, isso pode indicar:

            1. **Manipula√ß√£o intencional**: Fraude, falsifica√ß√£o ou fabrica√ß√£o de dados
            2. **Erros sistem√°ticos**: Problemas na coleta ou processamento dos dados
            3. **Anomalias naturais**: Efeitos de pol√≠ticas, regras ou limites aplicados aos dados
            4. **Caracter√≠sticas espec√≠ficas do dom√≠nio**: Alguns conjuntos de dados naturalmente n√£o seguem a Lei de Benford

            ### Limita√ß√µes

            - N√£o √© aplic√°vel a conjuntos pequenos de dados (geralmente n < 100)
            - N√∫meros atribu√≠dos (como c√≥digos postais ou n√∫meros de telefone) n√£o seguem a lei
            - N√∫meros com limites m√≠nimos ou m√°ximos definidos podem apresentar desvios
            - Nem todos os conjuntos de dados naturais seguem a Lei de Benford

            ### M√©tricas de An√°lise

            Esta ferramenta utiliza as seguintes m√©tricas:

            - **Teste Chi-Quadrado (œá¬≤)**: Avalia estatisticamente a signific√¢ncia dos desvios
            - **Valor-p**: Indica a probabilidade de observar desvios t√£o extremos quanto os observados, assumindo que a Lei de Benford √© verdadeira
            - **MAD (Mean Absolute Deviation)**: M√©dia dos desvios absolutos entre frequ√™ncias observadas e esperadas
            - **SAD (Sum of Absolute Differences)**: Soma total dos desvios absolutos

            ### Interpreta√ß√£o dos Resultados

            - **Valor-p < 0.05**: Indica desvio estatisticamente significativo da Lei de Benford
            - **MAD > 0.015**: Forte ind√≠cio de anomalias
            - **MAD entre 0.010 e 0.015**: Suspeita moderada de anomalias
            - **MAD entre 0.005 e 0.010**: Conformidade marginal, requer an√°lise contextual
            - **MAD < 0.005**: Boa conformidade com a Lei de Benford
            """)

        # Adicionar visualiza√ß√£o da distribui√ß√£o de Benford
        st.subheader("Visualiza√ß√£o da Lei de Benford")

        # Criar dados para visualiza√ß√£o
        benford_data = pd.DataFrame({
            'D√≠gito': range(1, 10),
            'Probabilidade (%)': np.log10(1 + 1 / np.arange(1, 10)) * 100
        })

        # Gr√°fico da Lei de Benford
        fig_benford = px.bar(benford_data, x='D√≠gito', y='Probabilidade (%)',
                             title='Distribui√ß√£o de Benford (Lei do Primeiro D√≠gito)',
                             labels={'Probabilidade (%)': 'Frequ√™ncia Esperada (%)'},
                             color_discrete_sequence=['#52BCA3'])

        fig_benford.update_layout(
            xaxis=dict(tickmode='linear', tick0=1, dtick=1),
            yaxis=dict(range=[0, 35])
        )

        st.plotly_chart(fig_benford, use_container_width=True)

        st.info("""
            **F√≥rmula da Lei de Benford**: 

            A probabilidade de um n√∫mero em um conjunto de dados come√ßar com o d√≠gito d (onde d = 1, 2, ..., 9) √©:

            P(d) = log‚ÇÅ‚ÇÄ(1 + 1/d)

            Por exemplo, a probabilidade do primeiro d√≠gito ser 1 √©:
            P(1) = log‚ÇÅ‚ÇÄ(1 + 1/1) = log‚ÇÅ‚ÇÄ(2) ‚âà 0.301 ou 30.1%
            """)

        st.markdown("""
            ### Refer√™ncias e Leituras Adicionais

            1. Benford, F. (1938). The law of anomalous numbers. Proceedings of the American Philosophical Society, 78(4), 551-572.

            2. Nigrini, M. J. (2012). Benford's Law: Applications for forensic accounting, auditing, and fraud detection. John Wiley & Sons.

            3. Durtschi, C., Hillison, W., & Pacini, C. (2004). The effective use of Benford's law to assist in detecting fraud in accounting data. Journal of Forensic Accounting, 5(1), 17-34.

            4. Drake, P. D., & Nigrini, M. J. (2000). Computer assisted analytical procedures using Benford's Law. Journal of Accounting Education, 18(2), 127-146.
            """)

    # Nota de rodap√©
    st.markdown("---")
    st.markdown(
        "**Benford Analytics** ¬© 2025 | Ferramenta desenvolvida para an√°lise de dados por meio da Lei de Benford")
    st.caption(
        "Vers√£o 1.0.0 | Esta ferramenta √© destinada
